{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab97bc3-eae4-4e00-a11f-ddb00c04203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c54961-9213-478f-87d0-dd817b3084f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 整合数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272fd75c-5144-4013-ab15-c557d9a8f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\", \"ednet5w\"]\n",
    "datasets_dic = {\"assist2009\": 0, \"algebra2005\": 1, \"bridge2algebra2006\": 2, \"nips_task34\": 3, \"ednet\": 4, \"peiyou\": 5, \"ednet5w\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a587ec2-abf4-4a75-b5af-32c7ca1b28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"dataset\":[], \"timestamps\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c31fbcbe-001f-4636-b07f-409e54e40514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df_train = pd.read_csv(f\"../data/{dataset}/train_valid_quelevel.csv\")\n",
    "    df_test = pd.read_csv(f\"../data/{dataset}/test_quelevel.csv\")\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    data_info_ = dict()\n",
    "    with open(f\"../data/{dataset}/keyid2idx.json\", \"r\") as f:\n",
    "        data_info = json.load(f)\n",
    "        for key in data_info:\n",
    "            data_info_.setdefault(key,dict())\n",
    "            try:\n",
    "                for item in data_info[key]:\n",
    "                    data_info_[key][data_info[key][item]] = item\n",
    "            except:\n",
    "                print(f\"{key}\")\n",
    "                continue\n",
    "    for i,row in df.iterrows():\n",
    "        uid = data_info_[\"uid\"][row[\"uid\"]]\n",
    "        # print(uid)\n",
    "        questions = row[\"questions\"].split(\",\")\n",
    "        # print(f\"questions:{questions}\")\n",
    "        concepts = row[\"concepts\"].split(\",\")\n",
    "        # print(f\"concepts:{concepts}\")\n",
    "        questions = [data_info_[\"questions\"][int(q)] for q in questions]\n",
    "        new_concepts = []\n",
    "        for ccc in concepts:\n",
    "            ccc = ccc.split(\"_\")\n",
    "            concept = [data_info_[\"concepts\"][int(c)] for c in ccc]\n",
    "            concept = \"_\".join(concept)\n",
    "            new_concepts.append(concept)\n",
    "        new_data[\"fold\"].append(row[\"fold\"])\n",
    "        new_data[\"uid\"].append(uid)\n",
    "        new_data[\"questions\"].append(\",\".join(questions))\n",
    "        new_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "        new_data[\"responses\"].append(row[\"responses\"])\n",
    "        new_data[\"dataset\"].append(dataset)\n",
    "        if \"timestamps\" in row:\n",
    "            new_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "        else:\n",
    "            new_data[\"timestamps\"].append(\",\".join([str(i) for i in range(len(questions))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a2910-aca1-4efe-8284-e14d2919dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e66f02-0ceb-4eef-a843-3c8a613e7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(f\"../data/pretrain/train_valid_quelevel_pretrain.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce83036-7a79-42bf-a928-1b8aa67468c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea8c4f-cd6f-4701-ba07-882edbdd96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort = pd.read_csv('../data/pretrain/train_valid_quelevel_pretrain.csv')\n",
    "df_sort = df_sort.sort_values(by='uid',ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa71f4d-f21a-4c11-a76b-79aea9d61246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d3b1d-b140-4883-a336-6f2f430618c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 完成数据映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f7c257-4566-4b11-bf17-387e46cd4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mapping_que(df):\n",
    "    id_keys = [\"questions\", \"concepts\", \"uid\"]\n",
    "    dres = dict()\n",
    "    dkeyid2idx = dict()\n",
    "    # print(f\"df.columns: {df.columns}\")\n",
    "    flag = True #判定数据集有没有变化\n",
    "    pre_data = \"assist2009\"\n",
    "    for key in df.columns:\n",
    "        if key not in id_keys:\n",
    "            dres[key] = df[key]\n",
    "    for i, row in df.iterrows():\n",
    "        dataset = row[\"dataset\"]\n",
    "        if dataset != \"ednet5w\":\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    if dataset == \"assist2009\":\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = 0\n",
    "                                        flag = False\n",
    "                                    else:\n",
    "                                        # print(f\"key:{key}, dataset:{dataset}, pre_data:{pre_data}\")\n",
    "                                        # print(f\"error:{dkeyid2idx[key][pre_data]}\")\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][pre_data].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                # dkeyid2idx[key][dataset][sub_id] = cnt+1\n",
    "                            sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "            pre_data = dataset\n",
    "        else:\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id in dkeyid2idx[key][\"ednet\"]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][\"ednet\"][sub_id]))\n",
    "                            elif sub_id not in dkeyid2idx[key][\"ednet\"] and sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][\"ednet\"].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            elif sub_id in dkeyid2idx[key][dataset]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "    finaldf = pd.DataFrame(dres)\n",
    "    return finaldf, dkeyid2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2877aff7-9f0b-4313-b693-8659c13e070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf, dkeyid2idx = id_mapping_que (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46318a2a-fafe-4835-a11e-c5099fc06a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/pretrain/keyid2idx.json\", \"w\") as f:\n",
    "    json.dump(dkeyid2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc9b9c-cdeb-4268-aa2c-39afc8109c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dkeyid2idx['questions']['ednet'].values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eddf7e-9906-4a2d-bd9d-c8a8edfce816",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(dkeyid2idx['questions']['ednet5w'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8793e2-4183-46f4-a401-783bfda64acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(finaldf[\"questions\"]):\n",
    "    row_ = row.split(\",\")\n",
    "    try:\n",
    "        \n",
    "        row_ = [int(x) for x in row_]\n",
    "    except:\n",
    "        print(i,row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7f015-dc8b-47ff-aced-dc2f41b6d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dkeyid2idx['questions']['bridge2algebra2006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295a4be-fc97-4540-bade-7465eaf562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dkeyid2idx['questions']['algebra2005'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ccf64-ad62-40e7-8eaa-88a9555388e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dkeyid2idx['questions']['ednet5w'].values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948a628-c6ef-47c9-8d4a-ad2b5fd977eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 计算一题对应最多知识点数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9345805-86b9-46e4-a429-03ecda3f46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_concepts(df):\n",
    "    max_concepts = 1\n",
    "    for i, row in df.iterrows():\n",
    "        cs = row[\"concepts\"].split(\",\")\n",
    "        num_concepts = max([len(c.split(\"_\")) for c in cs])\n",
    "        if num_concepts >= max_concepts:\n",
    "            max_concepts = num_concepts\n",
    "    return max_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34fb41-ca45-4ec1-acf3-3eb68df042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concepts = get_max_concepts(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90242d-0b59-422c-8b3f-1db5dd2bf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c972c2-6d72-4131-9816-d7e688601990",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 数据统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e06f6591-9357-406b-bbdd-07d10aaeac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calStatistics(df, stares, key):\n",
    "    allin, allselect = 0, 0\n",
    "    allqs, allcs = set(), set()\n",
    "    for i, row in df.iterrows():\n",
    "        rs = row[\"responses\"].split(\",\")\n",
    "        curlen = len(rs) - rs.count(\"-1\")\n",
    "        allin += curlen\n",
    "        if \"selectmasks\" in row:\n",
    "            ss = row[\"selectmasks\"].split(\",\")\n",
    "            slen = ss.count(\"1\")\n",
    "            allselect += slen\n",
    "        if \"concepts\" in row:\n",
    "            cs = row[\"concepts\"].split(\",\")\n",
    "            fc = list()\n",
    "            for c in cs:\n",
    "                cc = c.split(\"_\")\n",
    "                fc.extend(cc)\n",
    "            curcs = set(fc) - {\"-1\"}\n",
    "            allcs |= curcs\n",
    "        if \"questions\" in row:\n",
    "            qs = row[\"questions\"].split(\",\")\n",
    "            curqs = set(qs) - {\"-1\"}\n",
    "            allqs |= curqs\n",
    "    stares.append(\",\".join([str(s) for s in [key, allin, df.shape[0], allselect]]))\n",
    "    return allin, allselect, len(allqs), len(allcs), df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6877f-27de-4d68-9a30-5703d3e0af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf[finaldf.dataset==\"ednet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9834ac-fdff-4aed-854f-010b570db998",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum = calStatistics(df=finaldf, stares=[], key=\"original train+valid question level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc205a1-600c-4a3a-8f1c-f4d18b9b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e18d69-1d27-49cb-98ec-c95ddbba6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    final_sub_df = finaldf[finaldf.dataset==data]\n",
    "    ins_, ss_, qs_, cs_, seqnum_ = calStatistics(df=final_sub_df, stares=[], key=\"original train+valid question level\")\n",
    "    print(f\"dataset:{data}, ins_:{ins_}, ss_:{ss_}, qs_:{qs_}, cs_:{cs_}, seqnum_:{seqnum_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ce1ff-6c9f-4df2-b8a3-ce7658e89c95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 把数据集划分成sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5d13b-42c5-4d19-8a0f-73ae74a7184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sequences(df, effective_keys, min_seq_len=3, maxlen = 200, pad_val = -1):\n",
    "    save_keys = list(effective_keys) + [\"selectmasks\"]\n",
    "    dres = {\"selectmasks\": []}\n",
    "\n",
    "    dropnum = 0\n",
    "    for i, row in df.iterrows():\n",
    "        dcur = save_dcur(row, effective_keys)\n",
    "\n",
    "        rest, lenrs = len(dcur[\"responses\"]), len(dcur[\"responses\"])\n",
    "        j = 0\n",
    "        while lenrs >= j + maxlen:   \n",
    "            rest = rest - (maxlen)\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    dres[key].append(\",\".join(dcur[key][j: j + maxlen]))#[str(k) for k in dcur[key][j: j + maxlen]]))\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * maxlen))\n",
    "\n",
    "            j += maxlen\n",
    "        if rest < min_seq_len:# delete sequence len less than min_seq_len\n",
    "            dropnum += rest\n",
    "            continue\n",
    "        \n",
    "        pad_dim = maxlen - rest\n",
    "        for key in effective_keys:\n",
    "            dres.setdefault(key, [])\n",
    "            if key not in ONE_KEYS:\n",
    "                paded_info = np.concatenate([dcur[key][j:], np.array([pad_val] * pad_dim)])\n",
    "                dres[key].append(\",\".join([str(k) for k in paded_info]))\n",
    "            else:\n",
    "                if key == \"dataset\":\n",
    "                    dres[key].append(datasets_dic[dcur[key]])\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "        dres[\"selectmasks\"].append(\",\".join([\"1\"] * rest + [str(pad_val)] * pad_dim))\n",
    "    \n",
    "    # after preprocess data, report\n",
    "    dfinal = dict()\n",
    "    for key in ALL_KEYS:\n",
    "        if key in save_keys:\n",
    "            dfinal[key] = dres[key]\n",
    "    finaldf = pd.DataFrame(dfinal)\n",
    "    print(f\"dropnum: {dropnum}\")\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e9ded8-0c8f-44fa-8d8f-69097035d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dcur(row, effective_keys):\n",
    "    dcur = dict()\n",
    "    for key in effective_keys:\n",
    "        if key not in ONE_KEYS:\n",
    "            dcur[key] = row[key].split(\",\")#[int(i) for i in row[key].split(\",\")]\n",
    "        else:\n",
    "            dcur[key] = row[key]\n",
    "    return dcur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48ef6f3-aec4-4c10-968e-442a0771f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_KEYS = [\"fold\", \"uid\",\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea7ab8d6-cc0b-49ec-868a-61eca83840e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_KEYS = [\"fold\", \"uid\", \"dataset\", \"questions\", \"concepts\", \"responses\", \"timestamps\", \"usetimes\", \"selectmasks\", \"is_repeat\", \"qidxs\", \"rest\", \"orirow\",\"cidxs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2558d9f-3d08-4dc1-8bf3-f5fc3b1fe15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs = generate_sequences(df=finaldf, effective_keys={\"uid\", \"dataset\", \"questions\",\"concepts\",\"responses\",\"fold\", \"timestamps\"}, min_seq_len=3, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5660e0-d5d6-46ea-8f50-17089d07b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum = calStatistics(df=split_seqs, stares=[], key=\"train+valid sequences question level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36250bc1-32cf-4d86-b8d6-77daed7d1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5f58c-7ea2-4e7b-b91c-81e4975f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95e326-70c1-459d-ae09-a4c71ccccdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51c1c9-34e1-4717-87aa-51e61ce7950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24527f68-e274-4e0b-84d1-006c3b231ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = split_seqs\n",
    "test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs['dataset'] = test_seqs['dataset'].apply(lambda x: datasets_dic[x] if x in datasets_dic else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656336e8-dc45-458e-8fb5-c97cc34f26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs.to_csv(f\"../data/pretrain/train_valid_sequences_quelevel_200.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703b6b0-460c-4da1-a4df-8f510f408237",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv(f\"../data/pretrain/train_valid_quelevel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fe80b-5baf-406a-afcc-7556eb5eec9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 完成测试集映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13c31db8-e908-4df6-b8e5-ffca1729acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"ednet5w\", \"peiyou\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96de9131-1ade-4806-8f43-a9e5ac415e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset(datasets):\n",
    "    new_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"dataset\":[], \"timestamps\":[]}\n",
    "    for dataset in datasets:\n",
    "        datapath = f\"../data/{dataset}/test_quelevel.csv\"\n",
    "        df = pd.read_csv(datapath)\n",
    "        data_info_ = dict()\n",
    "        with open(f\"../data/{dataset}/keyid2idx.json\") as f:\n",
    "            data_info = json.load(f)\n",
    "            for key in data_info:\n",
    "                data_info_.setdefault(key,dict())\n",
    "                try:\n",
    "                    for item in data_info[key]:\n",
    "                        data_info_[key][data_info[key][item]] = item\n",
    "                except:\n",
    "                    print(f\"{key}\")\n",
    "                    continue\n",
    "        for i,row in df.iterrows():\n",
    "            uid = data_info_[\"uid\"][row[\"uid\"]]\n",
    "            questions = row[\"questions\"].split(\",\")\n",
    "            # print(f\"questions:{questions}\")\n",
    "            concepts = row[\"concepts\"].split(\",\")\n",
    "            # print(f\"concepts:{concepts}\")\n",
    "            questions = [data_info_[\"questions\"][int(q)] for q in questions]\n",
    "            new_concepts = []\n",
    "            for ccc in concepts:\n",
    "                ccc = ccc.split(\"_\")\n",
    "                concept = [data_info_[\"concepts\"][int(c)] for c in ccc]\n",
    "                concept = \"_\".join(concept)\n",
    "                new_concepts.append(concept)\n",
    "            new_data[\"fold\"].append(row[\"fold\"])\n",
    "            new_data[\"uid\"].append(uid)\n",
    "            new_data[\"questions\"].append(\",\".join(questions))\n",
    "            new_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "            new_data[\"responses\"].append(row[\"responses\"])\n",
    "            new_data[\"dataset\"].append(dataset)\n",
    "            if \"timestamps\" in row:\n",
    "                new_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "            else:\n",
    "                new_data[\"timestamps\"].append(\",\".join([str(i) for i in range(len(questions))]))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40106133-1b4c-449d-86b3-89813a449527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n",
      "max_concepts\n"
     ]
    }
   ],
   "source": [
    "new_data = map_dataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5622ff5-c2b4-4664-8fa4-c7ac1fbaa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cf9a627-303f-44bf-ac6f-62a8a6631e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>uid</th>\n",
       "      <th>questions</th>\n",
       "      <th>concepts</th>\n",
       "      <th>responses</th>\n",
       "      <th>dataset</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>77949</td>\n",
       "      <td>93375,93448,93394,93453,93467,93380,93411,8594...</td>\n",
       "      <td>2_37_70,2_37_48_77,2_37_70,2_37_48_77,2_37_48_...</td>\n",
       "      <td>0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0</td>\n",
       "      <td>assist2009</td>\n",
       "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>82929</td>\n",
       "      <td>66079,52813,66485,97860</td>\n",
       "      <td>49_50,49,49,50</td>\n",
       "      <td>1,1,1,1</td>\n",
       "      <td>assist2009</td>\n",
       "      <td>0,1,2,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>78575</td>\n",
       "      <td>84985,84635,84614,84595,84602,84615,84591,8623...</td>\n",
       "      <td>309,310,309,309,309,309,309,65,65,65,65,65,50,...</td>\n",
       "      <td>0,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,...</td>\n",
       "      <td>assist2009</td>\n",
       "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>79833</td>\n",
       "      <td>51010,51009,50992,50987,85716,85693,85750,8569...</td>\n",
       "      <td>310,310,310,310,49,49,49,49,50,50,50,50,50,49_...</td>\n",
       "      <td>0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,...</td>\n",
       "      <td>assist2009</td>\n",
       "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>83292</td>\n",
       "      <td>53265,53313,53330,53321,53319,53299,66701,6663...</td>\n",
       "      <td>51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,2...</td>\n",
       "      <td>0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,...</td>\n",
       "      <td>assist2009</td>\n",
       "      <td>0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold    uid                                          questions  \\\n",
       "0    -1  77949  93375,93448,93394,93453,93467,93380,93411,8594...   \n",
       "1    -1  82929                            66079,52813,66485,97860   \n",
       "2    -1  78575  84985,84635,84614,84595,84602,84615,84591,8623...   \n",
       "3    -1  79833  51010,51009,50992,50987,85716,85693,85750,8569...   \n",
       "4    -1  83292  53265,53313,53330,53321,53319,53299,66701,6663...   \n",
       "\n",
       "                                            concepts  \\\n",
       "0  2_37_70,2_37_48_77,2_37_70,2_37_48_77,2_37_48_...   \n",
       "1                                     49_50,49,49,50   \n",
       "2  309,310,309,309,309,309,309,65,65,65,65,65,50,...   \n",
       "3  310,310,310,310,49,49,49,49,50,50,50,50,50,49_...   \n",
       "4  51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,2...   \n",
       "\n",
       "                                           responses     dataset  \\\n",
       "0                    0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0  assist2009   \n",
       "1                                            1,1,1,1  assist2009   \n",
       "2  0,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,...  assist2009   \n",
       "3  0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,...  assist2009   \n",
       "4  0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,...  assist2009   \n",
       "\n",
       "                                          timestamps  \n",
       "0              0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15  \n",
       "1                                            0,1,2,3  \n",
       "2  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...  \n",
       "3  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...  \n",
       "4  0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2414743-1964-4252-b5e4-377e3ed2a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/pretrain/keyid2idx.json\",\"r\") as f:\n",
    "    dkeyid2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec8906-35fa-4243-82b0-4c92cc11958f",
   "metadata": {},
   "source": [
    "## 除ednet5w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    if dataset not in [\"ednet5w\"]:\n",
    "        sub_df = new_df[new_df.dataset==dataset]\n",
    "        new_map_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "        for i,row in sub_df.iterrows():\n",
    "            questions = [str(dkeyid2idx[\"questions\"][dataset][x]) for x in row[\"questions\"].split(\",\")]\n",
    "            concepts = row[\"concepts\"].split(\",\")\n",
    "            new_concepts = []\n",
    "            for ccc in concepts:\n",
    "                ccc = ccc.split(\"_\")\n",
    "                concept = [str(dkeyid2idx[\"concepts\"][dataset][c]) for c in ccc]\n",
    "                # concept = [str(dkeyid2idx.get(\"concepts\").get(dataset).get(c,len(dkeyid2idx['concepts'][dataset]))) for c in ccc]\n",
    "                concept = \"_\".join(concept)\n",
    "                new_concepts.append(concept)\n",
    "            new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "            new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "            new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "            new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "            new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "            new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "            new_map_df = pd.DataFrame(new_map_data)\n",
    "            new_map_df.to_csv(f\"{uni_path}/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22e123-bca3-400c-9c84-0d789bf59247",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\"]\n",
    "for dataset in datasets:\n",
    "    sub_df = new_df[new_df.dataset==dataset]\n",
    "    new_map_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "    for i,row in sub_df.iterrows():\n",
    "        questions = [str(dkeyid2idx[\"questions\"][dataset][x]) for x in row[\"questions\"].split(\",\")]\n",
    "        concepts = row[\"concepts\"].split(\",\")\n",
    "        dataset = datasets_dic[dataset]\n",
    "        new_concepts = []\n",
    "        for ccc in concepts:\n",
    "            ccc = ccc.split(\"_\")\n",
    "            concept = [str(dkeyid2idx[\"concepts\"][dataset][c]) for c in ccc]\n",
    "            # concept = [str(dkeyid2idx.get(\"concepts\").get(dataset).get(c,len(dkeyid2idx['concepts'][dataset]))) for c in ccc]\n",
    "            concept = \"_\".join(concept)\n",
    "            new_concepts.append(concept)\n",
    "        new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "        new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "        new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "        new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "        new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "        new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "        new_map_df = pd.DataFrame(new_map_data)\n",
    "        new_map_df.to_csv(f\"../data/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8030dde-a52d-4c32-a03f-4714bb6dfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"ednet5w\"]\n",
    "for dataset in datasets:\n",
    "    sub_df = new_df[new_df.dataset==dataset]\n",
    "    new_map_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "    for i,row in sub_df.iterrows():\n",
    "        questions = []\n",
    "        for x in row[\"questions\"].split(\",\"):\n",
    "            if x in dkeyid2idx[\"questions\"][\"ednet\"]:\n",
    "                questions.append(str(dkeyid2idx[\"questions\"][\"ednet\"][x]))\n",
    "            else:\n",
    "                questions.append(str(dkeyid2idx[\"questions\"][dataset][x]))\n",
    "        \n",
    "        concept = []\n",
    "        concepts = row[\"concepts\"].split(\",\")\n",
    "        new_concepts = []\n",
    "        for ccc in concepts:\n",
    "            ccc = ccc.split(\"_\")\n",
    "            concept = []\n",
    "            for c in ccc:\n",
    "                if c in dkeyid2idx['concepts'][\"ednet\"]:\n",
    "                    concept.append(str(dkeyid2idx[\"concepts\"][\"ednet\"][c]))\n",
    "                else:\n",
    "                    concept.append(str(dkeyid2idx[\"concepts\"][dataset][c]))\n",
    "            concept = \"_\".join(concept)\n",
    "            new_concepts.append(concept)\n",
    "        new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "        new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "        new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "        new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "        new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "        new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "        new_map_df = pd.DataFrame(new_map_data)\n",
    "        new_map_df.to_csv(f\"../data/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04700f11-4f80-497c-a7a5-b8d042d128cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080999a4-2662-4f8a-8860-08d1bf90df8c",
   "metadata": {},
   "source": [
    "## 生成window测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dbce821-f526-494f-af04-8faff2367e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_window_sequences(df, effective_keys, maxlen=200, pad_val=-1):\n",
    "    save_keys = list(effective_keys) + [\"selectmasks\"]\n",
    "    dres = {\"selectmasks\": []}\n",
    "    for i, row in df.iterrows():\n",
    "        dcur = save_dcur(row, effective_keys)\n",
    "        lenrs = len(dcur[\"responses\"])\n",
    "        if lenrs > maxlen:\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    dres[key].append(\",\".join(dcur[key][0: maxlen]))#[str(k) for k in dcur[key][0: maxlen]]))\n",
    "                else:\n",
    "                    if key == \"dataset\":\n",
    "                        dres[key].append(datasets_dic[dcur[key]])\n",
    "                    else:\n",
    "                        dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * maxlen))\n",
    "            for j in range(maxlen+1, lenrs+1):\n",
    "                for key in effective_keys:\n",
    "                    dres.setdefault(key, [])\n",
    "                    if key not in ONE_KEYS:\n",
    "                        dres[key].append(\",\".join([str(k) for k in dcur[key][j-maxlen: j]]))\n",
    "                    else:\n",
    "                        if key == \"dataset\":\n",
    "                            dres[key].append(datasets_dic[dcur[key]])\n",
    "                        else:\n",
    "                            dres[key].append(dcur[key])\n",
    "                dres[\"selectmasks\"].append(\",\".join([str(pad_val)] * (maxlen - 1) + [\"1\"]))\n",
    "        else:\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    pad_dim = maxlen - lenrs\n",
    "                    paded_info = np.concatenate([dcur[key][0:], np.array([pad_val] * pad_dim)])\n",
    "                    dres[key].append(\",\".join([str(k) for k in paded_info]))\n",
    "                else:\n",
    "                    if key == \"dataset\":\n",
    "                        dres[key].append(datasets_dic[dcur[key]])\n",
    "                    else:\n",
    "                        dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * lenrs + [str(pad_val)] * pad_dim))\n",
    "    \n",
    "    dfinal = dict()\n",
    "    for key in ALL_KEYS:\n",
    "        if key in save_keys:\n",
    "            # print(f\"key: {key}, len: {len(dres[key])}\")\n",
    "            dfinal[key] = dres[key]\n",
    "    finaldf = pd.DataFrame(dfinal)\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7c01706-118a-49c5-acc8-ca9a488827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\", \"ednet5w\"]\n",
    "for data in datasets:\n",
    "    test_df = pd.read_csv(f\"../data/{data}/test_quelevel_pretrain.csv\")\n",
    "    test_window_seqs = generate_window_sequences(test_df, list({\"uid\",\"dataset\",\"questions\",\"concepts\",\"responses\",\"fold\"}), maxlen=200)\n",
    "    test_window_seqs['dataset'] = test_window_seqs['dataset'].apply(lambda x: datasets_dic[x] if x in datasets_dic else x)\n",
    "    test_window_seqs.to_csv(f\"../data/{data}/test_window_sequences_quelevel_pretrain_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e5b0008-b885-493f-9a1d-f3a0e1069bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fold</th>\n",
       "      <th>uid</th>\n",
       "      <th>dataset</th>\n",
       "      <th>questions</th>\n",
       "      <th>concepts</th>\n",
       "      <th>responses</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>62713</td>\n",
       "      <td>ednet5w</td>\n",
       "      <td>321188,321189,321190,321191,321194,321193,3211...</td>\n",
       "      <td>862_815_795,863_864_800,865_864_800,817_837_79...</td>\n",
       "      <td>1,1,1,0,0,1,1,1,1,0,0,0,1,1,0,0,1,0,0,0,0,0,1,...</td>\n",
       "      <td>1511153394361,1511153418829,1511153454202,1511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>600348</td>\n",
       "      <td>ednet5w</td>\n",
       "      <td>328109,323246,322816,328609,321075</td>\n",
       "      <td>787,802_851_800_796,812,929,804_802_803_807_799</td>\n",
       "      <td>0,0,1,0,1</td>\n",
       "      <td>1558769457672,1558769672646,1558769783754,1558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>267973</td>\n",
       "      <td>ednet5w</td>\n",
       "      <td>322801,325567,322550,325629,321156,322861,3223...</td>\n",
       "      <td>929,786,888,790,817_818_796_807,807_799_802_80...</td>\n",
       "      <td>0,0,1,1,1,1,0,0,0</td>\n",
       "      <td>1538027536560,1538027585077,1538027619510,1538...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>694917</td>\n",
       "      <td>ednet5w</td>\n",
       "      <td>322928,331624,322059,321443,324253,321087</td>\n",
       "      <td>856,787,787,811,812,813</td>\n",
       "      <td>1,1,1,1,0,0</td>\n",
       "      <td>1564145302287,1564145326225,1564145378860,1564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>24943</td>\n",
       "      <td>ednet5w</td>\n",
       "      <td>321291,321292,321293,321294,321295,321296,3212...</td>\n",
       "      <td>890_815_800,826_815_795,890_815_800,814_815_80...</td>\n",
       "      <td>1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,...</td>\n",
       "      <td>1499416860472,1499416882519,1499416902846,1499...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fold     uid  dataset  \\\n",
       "0           0    -1   62713  ednet5w   \n",
       "1           1    -1  600348  ednet5w   \n",
       "2           2    -1  267973  ednet5w   \n",
       "3           3    -1  694917  ednet5w   \n",
       "4           4    -1   24943  ednet5w   \n",
       "\n",
       "                                           questions  \\\n",
       "0  321188,321189,321190,321191,321194,321193,3211...   \n",
       "1                 328109,323246,322816,328609,321075   \n",
       "2  322801,325567,322550,325629,321156,322861,3223...   \n",
       "3          322928,331624,322059,321443,324253,321087   \n",
       "4  321291,321292,321293,321294,321295,321296,3212...   \n",
       "\n",
       "                                            concepts  \\\n",
       "0  862_815_795,863_864_800,865_864_800,817_837_79...   \n",
       "1    787,802_851_800_796,812,929,804_802_803_807_799   \n",
       "2  929,786,888,790,817_818_796_807,807_799_802_80...   \n",
       "3                            856,787,787,811,812,813   \n",
       "4  890_815_800,826_815_795,890_815_800,814_815_80...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  1,1,1,0,0,1,1,1,1,0,0,0,1,1,0,0,1,0,0,0,0,0,1,...   \n",
       "1                                          0,0,1,0,1   \n",
       "2                                  0,0,1,1,1,1,0,0,0   \n",
       "3                                        1,1,1,1,0,0   \n",
       "4  1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,...   \n",
       "\n",
       "                                          timestamps  \n",
       "0  1511153394361,1511153418829,1511153454202,1511...  \n",
       "1  1558769457672,1558769672646,1558769783754,1558...  \n",
       "2  1538027536560,1538027585077,1538027619510,1538...  \n",
       "3  1564145302287,1564145326225,1564145378860,1564...  \n",
       "4  1499416860472,1499416882519,1499416902846,1499...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc5ab0-adde-4582-8fe1-b494797544d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window_seqs = generate_window_sequences(test_df, list({\"uid\",\"questions\",\"concepts\",\"responses\",\"fold\"}), maxlen=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646cc0e-b4e4-4d43-b85e-df570ce2507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fd521-c46d-4840-a01c-e083444b8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 你的数据\n",
    "data = [229471, 513430, 1463212, 1109911, 462626, 4719979, 4446825]\n",
    "\n",
    "# 数据标签\n",
    "labels = ['229471', '513430', '1463212', '1109911', '462626', '4719979', '4446825']\n",
    "\n",
    "# 创建饼图\n",
    "plt.pie(data, labels = labels, autopct='%1.1f%%')\n",
    "\n",
    "# 添加标题\n",
    "plt.title('数据饼图')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e4009-3a69-484a-94d9-51510453f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 你的数据\n",
    "data = [229471, 513430, 1463212, 1109911, 462626, 4719979, 4446825]\n",
    "\n",
    "# 数据标签\n",
    "labels = [\"AS2009\", \"AL2005\", \"BD2006\", \"NIPS34\", \"EdNet\", \"EdNet5w\", \"Peiyou\"]\n",
    "\n",
    "# 创建饼图\n",
    "plt.pie(data, labels = labels, autopct='%1.1f%%')\n",
    "\n",
    "# 添加标题\n",
    "plt.title('Pretrain data distribution')\n",
    "\n",
    "plt.savefig(\"pie_chart.pdf\", format='pdf')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e1ab8-a47a-4f5f-b88d-5d182fed7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/autodl-nas/project/pykt_nips2022/examples/best_model_path/ednet5w/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ecc3b-ca13-4cd9-914f-e309eaa0b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c54f5-04aa-48af-bef6-863ca5457548",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c45346-ddc5-44fa-8ec4-85404687010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_path = os.listdir(os.path.join(path, model))\n",
    "    for best_path in model_path:\n",
    "        print(\"- \"+os.path.join(path, model, best_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aa057-8378-4783-bbaa-8e43a087d5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89853148-03d4-4c01-8e1f-e6005d6c053b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
